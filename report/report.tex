\documentclass[11pt,twoside,a4paper]{article}
\usepackage{tabularx}
\begin{document}
\title{Accessibility of maps for the blind on mobile platforms}
\author{Daniel Dalton}
\date{June 2015}
\maketitle
\tableofcontents

\begin{abstract}
Maps or mobile applications that present maps on screen are not usable
by the blind without modification. Although many applications exist to
aide with navigation and mobility, few options exist for understanding
spatial and relative layout of a map.
The current strategies that are used
to present map data to the blind will be explored along with
their benefits and limitations. A mobile solution utilising a web
service and IOS application will be proposed to provide access to maps
for the blind in the hope of overcoming some of the current limitations.
\end{abstract}

\section{Introduction}
Traditionally, it has been difficult for a vision impaired person to
access and interpret a map of a particular area. There are limited
options currently available to access this type of spatial information
and those options currently available are not always practical or
realistic. Although over the last decade or so the increased
availability of navigation apps for mobile platforms has assisted with
this problem there are still many limitations in conveying spatial data
efficiently and effectively to a blind user.

The second complication of this problem is that a standard map aimed for
a visual user contains an overwhelming amount of data, which is
difficult to convey to a sight impaired user relying exclusively on
their finger tips or audio for such data. In addition sight impaired
users may require greater detail about their surroundings to
successfully navigate the region \cite{Haptimap2012}.

This project seeks to provide a mechanism for a blind or vision impaired
person to access a map of an area in a practical and timely manner
gaining the essential information they need to safely and confidently
navigate. This project relates to the retrieval of spatial information and human
computer interaction. Ultimately, the project will investigate the most
appropriate way to provide this spatial information for a given area to
a blind or vision impaired person utilising a mobile platform. This is a
conceptual and practical work.

\subsection{Goals and Objectives}
The aim of this project is to build a web service which has the ability
to produce a SVG graphic of a particular area. The image should render
streets, buildings and other places of interest of a neighbourhood. The
image can then be parsed by the GraVVITAS software for ipad developed by
Dr Cagatay Goncu. This will facilitate a blind or vision impaired user
to explore the graphical layout of the neighbourhood rendered by the
proposed web service. The produced SVG will contain the data required to
meet the requirements of this solution.

This research will investigate the following two areas:
\begin{enumerate}
\item Determine the most effective way to filter information from a map to a form which can be comprehended by someone without the ability to view it visually.
\item Investigating navigation techniques to navigate the presented information.
\end{enumerate}

Visual maps contain a considerable amount of information. Not all of
this is relevant, and it will need to be decided what is crucial
information and what is not. In addition useful information should be
presented on the produced map such as buildings within a university
campus for example.

Conveying the layout of the setting such as where buildings in a
university campus are relative to each other is the second aspect in
this research. Devising practical and efficient strategies for a blind
person to explore the map is critical to its success. The blind user can
not be expected to scan the map every time they are looking for
something in its entirety as this is time consuming and tedious.

Ultimately, it is hoped that the final product of the research will
allow a caller to pass a geographical location to the web service with
defined bounds and to have a SVG result returned. The SVG result will
be suitable for access by a blind person on ipad in an effective and
efficient manner. It is hoped that this can help vision impaired users
reliably understand their surroundings around them before they set off
on a trip. Secondly, it is hoped that this can be adapted to a smart
phone device such as Iphone so that the project can be taken advantage
of by a blind person while moving around in society although this is
likely a future addition to the project.

\section{Literature Review}
\subsection{Current Solutions}
\subsubsection{Tactile Graphics}
Historically, the most popular form of conveying diagrams to the vision
impaired including maps was by means of a tactile graphic, utilising ``swell paper'' and ``thirmoform diagrams''
\cite{mccallum2003}. Roads, buildings and other points of interest are
displayed tactically with supporting Braille labels in some cases so that
readers can identify what each raised point or line represents.

\subsubsection{Virtual Acoustic Map}
Another alternative is the ``Virtual Acoustic Map'', which associates
objects on the map with different audible sounds and uses these sounds
to convey the map data to the blind user. Another implementation is speech output of the layout
of streets including their direction and name \cite{Hoeckner2012}.

\subsubsection{Virtual Tactile Maps}
Virtual tactile maps are another approach to communicate map data to a
site impaired user. This type of presentation utilises tactile displays,
or other haptic devices such as ``joysticks'' and ``haptic mice''
\cite{Parente2003}. These devices are used to communicate the input and
output of the map with the user. In addition acoustic information is
sometimes used for greater detail.

\subsubsection{Mobile solutions}
With the innovation of mobile devices came innovative mechanisms to
present map data to a sight impaired user. Several approaches of this
nature were explored and presented in \cite{Kane2011}. Edge projection
is the first technique. This technique relies on projecting map objects
to two sides of the touch screen. The user can explore the map by moving
both hands simultaneously to locate the x and y projections. Having
discovered these the user can then move their hands inwards towards the
point of interest on the map. Neighbourhood browsing is another
technique used by mobile applications. The application calculates area
that is not occupied around each object and reclaims that area. The
result is when touching the screen the closest object is spoken to the
user. A gesture can exist to provide directions. Touch and speak is the
final approach utilising touch input and voice commands to overcome the
inefficiency of exploring the map.

Various mobile app solutions were explored first hand on the IOS and
Android platforms. They will be summarised here.

Apple's maps application facilitates exploring a map and gaining spatial
insight among other features. When Apple maps is presenting a map of
some location the user may explore with one finger to hear names of
streets, towns or larger areas such as cities and states (depending on
the zoom factor). If the map is showing streets the user can hold their
finger on a street to trace it. The user may also use standard voice
over flicks to flick between objects on the map eg. cities for a map of
Australia. However, such a technique will give the user very little
spatial layout information.  The user can control the map
easily. Scrolling the map left/right or up/down is straight
forward. Zooming is also very easy, but it seems hard to make the map
zoom in on a particular area such as Sydney for a map of
Australia. Double tapping the city to zoom in on and then zooming in
seems to work sometimes. As the zoom changes or the map is shifted voice
over will announce a quick summary of the map such as what is on
screen. Works OK, but sometimes overwhelming.
Apple maps was tested with a map of Australia. Exploring with one finger
was painful and time consuming as you must touch a specific area of the
map to hear the name of a place spoken. In other words there is a lot of
empty space on the map where the user is given no feedback as they move
their finger. Moving around the map is not particularly efficient.

Blind square is a very popular app among the vision impaired. The
description here is based off the app’s description in the app store as
`the app costs \$37 and could not be tested first hand \cite{BlindSquare}.
Blind square claims to be the most popular gps app for the blind. ``When
Blind Square has determined your location using your iOS-device’s GPS
capabilities, it will look up information about your surroundings on
FourSquare and Open Street Map. Employing unique algorithms, it will
then ascertain the information most useful to you and speak it in a
clear synthetic voice'' \cite{BlindSquare}. Blind square will announce places of interest
and your location as you move. If you set a destination it will also
indicate the clock direction of the place from you and the distance it
is from you has you move towards it. Blind square facilitates marking
your current location so that you can easily find this later on. It
appears that blind square is very good at speaking important information
back to the user, but does not provide a way for the blind user to
explore the area in a tactile fashion and gain a spatial layout
understanding.

Ariadne gps is an app available for ipad and Iphone. It has a variety of
navigational and mapping features. For the scope of this project the
mapping functionality will be described.
The app has two main features of interest, “explore an area” and “look
around”. Both these modes present a map to the user. Look around will
position the map to the location of the device in the direction that the
user is facing. When the map is shifted the user will hear which
direction it is shifted relative to the way they are facing
eg. ``forwards'', ``backwards'', ``left'' or ``right''. The explore area allows
the map to be positioned at some fixed address. Moving the map around
says east/west/north/south rather than left/right etc.
Both modes have exactly the same functionality. Moving the map around in
the four compass directions. After each motion the app will speak what
area the map is centred around and the radius size. Zooming in and
zooming out works with a pinch. The map will update and speak to the
user eg. “showing localities and cities” or “ streets and
numbers”. Otherwise, the map allows the user to explore the
neighbourhood by tracing their finger around the screen and street names
and intersections get announced along with places of interest
eg. “Monash university Clayton campus” and street numbers. The user can
locate a point on the screen and have the map re-calibrated and centred
around that point.

Intersection explorer is an android application by Google designed for
the vision impaired. It allows a user to navigate a neighbourhood with
their finger to explore streets and intersections to gain a spatial
layout of streets.
The user moves their finger around on the screen in a direction until
they hear that their is a street in the given direction that they would
like to follow. Releasing the finger will move down the street to the
next intersection. This pattern is repeated so that the user can
understand how streets are set out and intersect each
other. Unfortunately the app is only good for streets and
intersections. It does not announce any street numbers or places. It
does have some problems as many streets are spoken as “unnamed road”.

\subsection{Limitations of existing work}
Although the discussed solutions do a reasonable job at making maps
accessible to the sight impaired they do have some substantial
limitations. The manual techniques such as tactile graphics are very
resource intensive to produce. They require work on the part of a
sighted transcriber for every map that a blind user may wish to
explore. In addition this is an expensive process. The tactile maps are
not overly portable and can not be used while walking for instance.

The scope of this project is to develop a mobile solution to this
problem. The rest of the limitations will discuss those faced by current
apps on the market. As indicated apps such as apple maps are inefficient
to navigate and for instance do not speak when the user touches empty
space. The problem is that the map may potentially contain a vast amount
of empty space. Other apps such as intersection explorer do not show
places or points of interest on the map which is valuable information
for a blind user. 

Ariadne GPS is perhaps the best solution currently available. It has a
variety of features, but also some important limitations. Navigating the
map is still done by exploring with the finger tip which is relatively
slow and it only shows some places. It does not necessarily provide all
of the details that the user may require.

Although there are many other navigational apps designed for the vision
impaired these are designed primarily for guided directions or finding
places near by. They do not make any effort to present any form of map
or relative spatial layout information.

\subsection{Opportunities}
Presently, there is no solution which depicts buildings and their shapes
as well as entrances for example. In addition there is no way to
determine the relative spatial layout between two objects on the map
aside from tracing with the finger tip which is a fundamental point of
this research. However, perhaps most importantly filtering is quite
limited on all solutions. If the blind user is only interested in cafes
they will have a hard time locating these in among all of the other
points of interest on the map. This area will also be addressed by the
proposed solution.

\section{Requirements}

The project is broken into two components the user interface and web
service. The user interface relies on the web service to present the map
experience to the sight impaired user.

\subsection{User interface}
\subsubsection{Opening the map}
\textbf{Name:} Open map.\\
\textbf{Identifier:} UC1\\
\textbf{Description:}\\
Load a map of a given area of the user's choosing.\\
\textbf{Preconditions:}\\
The application has access to the web service.\\
\textbf{Postconditions:}\\
A map of the chosen area is presented provided the chosen location was
valid.

\noindent
\textbf{Basic course of action}\\
\begin{tabularx}{\textwidth}{ |X|X|}
  \hline
  \textbf{User} & \textbf{System}\\
  \hline
  1. User selects ``Use current location'' or ``Enter address manually''
  [Alt A] & \\
  \hline
  & 2. System presents the map centred around the desired region with
  default zoom factors and radius.\\
  \hline
\end{tabularx}

\noindent 
\textbf{Alternate course A}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \hline
  \textbf{User} & \textbf{System}\\
  \hline
  A1. The user selects ``enter address manually''. & \\
  \hline
  & A2. System displays text field for address input.\\
  \hline
  A3. User types address to centre map around. & A4. System populates
  auto-completion area of potential addresses.\\
  \hline
  A5. User makes the selection of the address. The use case now
  continues at step 2 in the basic course. & \\
  \hline
\end{tabularx}

\subsubsection{Filtering points of interest}
\noindent
\textbf{Name:} Points of interest\\
\textbf{Identifier:} UC2\\
\textbf{Description:}\\
Allow the user to pick points of interest they would like to see on the
map in addition to the basic features such as streets. This filtering is
done by displaying possible categories to filter. There shall be a wide
range of categories to select from for example ``cafe''.\\
\textbf{Preconditions:}\\
A map of a given area is loaded and being presented.\\
\textbf{Postconditions:}\\
The presented map now reflects the changes in the category filters.

\noindent
\textbf{Basic course of action:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{User} & \textbf{System}\\
  \hline
  1. User performs a two finger twist (roter gesture). & \\
  \hline
  & 2. System announces ``Points of interest''.\\
  \hline
  3. User flicks up or down until desired category is heard. & \\
  \hline
  4. Double tap anywhere on screen to activate selected
  category. & \\
  \hline
  & 5. System updates map to show points matching the newly selected
  category. [Alternate a].\\
  \hline
\end{tabularx}

\noindent
\textbf{Alternate course A}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{User} & \textbf{System}\\
  \hline
  & A5. This category is already being displayed on the map the result
  is to deactivate it and map no longer shows places of this type.\\
  \hline
  & A6. Use case ends.\\
  \hline
\end{tabularx}

\subsubsection{Showing a path between two points on the map}
\noindent
\textbf{Name:} Depict a path between two distinct points\\
\textbf{Identifier:} UC3\\
\textbf{Description:}\\
A user has two distinct points on the map they wish to find a path
between following roads and other pathways. This is not necessarily
trivial for a blind user to achieve.\\
\textbf{Preconditions:}\\
There is a map of an area being displayed on screen.\\
The map has at least two distinct points.\\
\textbf{Postconditions:}\\
Map is updated to play a unique tone whenever the newly created pathway
is touched or approached.\\
No change to map if a path could not be found.

\noindent
\textbf{Basic course of action:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{User} & \textbf{System}\\
  \hline
  1. User presses and holds their finger on point a, the first point. &
  \\
  \hline
  2. The user taps a second (distinct) point on the map (point B). & \\
  \hline
  3. The user releases both fingers & \\
  \hline
  & 4. System calculates and presents a path between the points on the
  map. An overview of this path is spoken. back to the user. [Alternate A]\\
  \hline
  5. User explores map with a single finger. & 6. When the user touches
  the path the pathway tone is played back to the user.\\
  \hline
\end{tabularx}

\noindent
\textbf{Alternate course A}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{User} & \textbf{System}\\
  \hline
  & A4. System could not find a path between the two points, error
  message is spoken.\\
  \hline
  & A5. Use case ends\\
  \hline
\end{tabularx}

\noindent
\textbf{Name:} Remove paths\\
\textbf{Identifier:} UC4\\
\textbf{Description:}\\
Clear the map of any paths if any have been created by UC3.\\
\textbf{Preconditions:}\\
Map of an area is currently being shown.\\
At least one pathway is depicted on the map otherwise it has no
effect.\\
\textbf{Postconditions:}\\
Remove all pathways from the map.

\noindent
\textbf{Basic course of action:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{User} & \textbf{System}\\
  \hline
  1. Two finger twist action (roter gesture). & \\
  \hline
  & 2. System announces ``clear paths''\\
  \hline
  3. User double taps anywhere on screen. & \\
  \hline
  & 4. System clears map of paths and speaks ``paths cleared''.\\
  \hline
\end{tabularx}

\subsubsection{Finding points on the map}
\noindent
\textbf{Name:} Locating points on the map\\
\textbf{Identifier:} UC5\\
\textbf{Description:}\\
It is time consuming for the user to explore the entire screen looking
for specific features on the map. Allow the user to hear the features
contained within a certain sub-area of the map.
\textbf{Preconditions:}\\
There is a map of an area being displayed on screen.\\
\textbf{Postconditions:}\\
No change to map.

\noindent
\textbf{Basic course of action:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{User} & \textbf{System}\\
  \hline
  1. User touches and holds their finger on a single point of the screen. & \\
  \hline
  2. The user draws a circle around their finger currently held on the
  map of any size. & \\
  \hline
  3. The user releases both fingers & \\
  \hline
  & 4. The system announces the streets and points of interest within
  the area defined by the circle relative to the initial centre point
  from step 1.\\
  \hline
  \hline
\end{tabularx}

\subsection{Web Service}

The web service is invoked by means of HTTP parameters by means of a
HTTP request. The following use cases will be necessary for the web
service to fulfill its requirements to the UI.

\subsubsection{Request an SVG map}
\noindent
\textbf{Name:} Produce SVG map\\
\textbf{Identifier:} UC6\\
\textbf{Description:}\\
Construct an SVG map of an area of certain bounds with data from one or
more third party services. Return the resulting data in the form of an
SVG image.\\
\textbf{Preconditions:}\\
Third party services are available\\
Request is a correctly formatted HTTP request.\\
Request contains at a minimum radius, latitude and longitude parameters.\\
\textbf{Postconditions:}\\
None\\

\noindent
\textbf{Basic course of action:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{Client} & \textbf{System hosting service}\\
  \hline
  1. Client provides a HTTP request with parameters radius, latitude, longitude,
  filter, paths. & \\
  \hline
  & 2. System contacts open maps and additional third party services to acquire data matching
  filter list. [Alternate A], [Alternate B], [Alternate C], [Alternate D]\\
  \hline
  & 3. System combines all retrieved data into a single accessible
  SVG.\\
  \hline
  & 4. System returns the svg.\\
  \hline
  5. Client receives the svg image. & \\
  \hline
\end{tabularx}

\noindent
\textbf{Alternate course A:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{Client} & \textbf{System hosting service}\\
  \hline
  & A2. Radius, latitude or longitude of the centre point is missing, return
  error code to client.\\
  \hline
  A3. Client receives error code. & \\
  \hline
  A4. Use case terminates. & \\
  \hline
\end{tabularx}

\noindent
\textbf{Alternate course B:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{Client} & \textbf{System hosting service}\\
  \hline
  & A2. One of the third party services is down return an error code
  indicating this to the client.\\
  \hline
  A3. Client receives error code that external services are down. & \\
  \hline
  A4. Use case terminates. & \\
  \hline
\end{tabularx}

\noindent
\textbf{Alternate course C:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{Client} & \textbf{System hosting service}\\
  \hline
  & A2. Filter parameter contains a value such as ``cafe'' or
  ``restaurant'', system constructs a suitable query.\\
  \hline
  & A3. The query is sent to the appropriate service.\\
  \hline
  & A4. System receives the place data back and converts it to a
  standardised form.\\
  \hline
  & A5. Use case continues at step 3.\\
  \hline
\end{tabularx}

\noindent
\textbf{Alternate course D:}\\
\begin{tabularx}{\textwidth}{ |X|X| }
  \textbf{Client} & \textbf{System hosting service}\\
  \hline
  & A2. System creates objects to be placed on the SVG representing a
  path between two unique points within the SVG.\\
  \hline
  & A3. Use case continues at 3.\\
  \hline
\end{tabularx}

\section{Design}

\subsection{User Interface Design}

As specified within the requirements there are four key features of this
application: loading of the map around a given area which includes
features within a specified radius, the filtering of map features,
marking a pathway/route between two points on the map and enhancing the
exploration of the map from the point of view of a sight impaired
user. The design of each of these four aspects will be discussed.

\subsubsection{Opening the map}

When the application is first invoked it is logical to display a map to
the user of the current location. This is done by using the current
location as determined by the device's location services. The user can
then begin exploring the map of where they currently are.

If the user wishes to look around another area they may load the map of
this area by supplying the address. To do this the user will make use of
the rota or two finger twist method. They will repeat this until they
hear ``search''. A double tap with a single finger will present the
search screen.

The search screen is now active. This screen will consist of an input
text field at the top labeled ``Address''. A search button will be
located to the right of this. When the user is within the text field the
system keyboard will be active and they may begin typing a location. As
the location is being typed the potential candidate addresses appear
below the text field. The user then either presses the search button or
selects one of the suggested addresses.

The map may fail to load due to either an invalid address being supplied
or other area. If this is the case a standard error dialog should be
displayed informing the user of such an event. The user can dismiss this
dialog returning them to the search screen again.

If the result is successful the map screen which appeared initially when
the application was launched will re-appear, but this time for a map of
the selected location.

The two finger flick can be used to cycle to the ``radius''
option. Flicking up will decrease the radius of the map while flicking
down will increase the radius of the map. When the user finds a radius
they are happy with they will double tap to refresh the map with the new
radius. The radius specifies the points that shall be included within
the map. For example a radius of 500 m will include only features that
are within 500 metres of the centre point that the map is centred
around.

The map screen may be explored with a single finger. The feedback
provided is controlled by the graViewer software. As the finger moves
objects under the finger are announced to the user. These objects
include roads and points of interest. Audio tones will be played for
additional audible feedback. In addition the vibration finger sensors
may be used for haptic feedback when exploring the map.

\subsubsection{Filtering points of interest}

A key consideration for the project is how to best filter the map so
that it can be navigated in a practical manner. The user will have the
liberty to choose what appears on the map so they can choose what fits
within their user capabilities.

Assuming the map screen is active showing a map of an area the user may
use the conventional two finger twist voice over command until they hear
``points of interest''. The user will then flick up and down with one
finger to cycle between the potential options such as streets, cafes,
restaurants, fast food, buildings, public transport etc. The user can
double tap on any of these options. If the option was not previously
selected the user will hear ``checked'' and the map will be updated to
include features matching that parameter. eg. if cafes was now checked
the map would be populated with all cafes within the mapped region. If
the item was already selected eg. cafes a single finger double tap would
announce ``unchecked'', and the cafes on the map would disappear. Note
that the state of any of the options in this list (cafes, streets etc.)
should have their state announced after the category name either checked
or unchecked. 

The user will have the freedom to select or unselect whatever items they
would prefer. The map will be initialised with streets shown only.

\subsubsection{Showing a path between two points on the map}

A very important use case is traversing from a starting point to a
destination point.

Assuming the map screen is being displayed showing a map of a
region. The user will touch and hold any area within the bounds of the
map. That is the point must actually reside on the map such as a street
or point of interest. The user will then move their second finger around the map locating the destination point. The user will then tap quickly
on this second point. After performing the tap the first finger will be
released. If an error occurs the system will announce this otherwise a
pathway/route between the two points will be plotted on the map.

The pathway will be in a different colour to other features on the
map. As a result when the path is touched the street name will be
announced, but a unique tone specific to the path will be played. This
will reassure the user that they are indeed following the path.

Between stages of the path eg. where the route twists and turns the
relevant directional instructions will be spoken. For instance if the
user is traversing along the route over street a, as the route is about
to turn the system will announce ``route turns left onto street b 400
metres''. This will be very helpful to not only give the user
directional instructions, for real world navigation, but it will make
following the route much easier on the screen of the ipad. Less time is
wasted trying to constantly locate the route.

The starting points and end points of the route will also be marked
accordingly.

The rota action (two finger twist) can be used to navigate to ``clear
paths''. When this is double tapped the pathways will be removed as will
the directional points discussed above. The map will behave normally
again.

\subsubsection{Finding points on the map}

A challenging task for a blind user is to find a certain point of
interest on a map that is potentially quite small hidden within other
features. If the user has some idea where this is they can place their
first finger roughly where they think this is. Next they will draw a
circle around their first finger. The circle can be as large or as small
as the user desires. All features that lie within this circle will be
announced to the user including their direction from the centre
point. The centre point is the point where the initial finger was first
placed. For example ``building 1 12 o'clock''. The features will be
announced in terms of distance. That is those closest to the centre are
spoken first followed by those further out. The speech can be
interrupted at any time by touching another point on the map.

Note, the shape drawn does not need to be a circle just a general
outline around the shape providing a boundary for including points.

\subsection{Web Service Design}

\section{Implementation}

\section{Results and Evaluation}

\section{Conclusion}
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv}
\end{document}
